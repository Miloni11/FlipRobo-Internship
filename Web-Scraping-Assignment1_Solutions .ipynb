{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB SCRAPING ASSIGNMENT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1. Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1 class=\"firstHeading\" id=\"firstHeading\">Main Page</h1>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>,\n",
       " <h2>Navigation menu</h2>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-personal-label\">\n",
       " <span>Personal tools</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-namespaces-label\">\n",
       " <span>Namespaces</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-variants-label\">\n",
       " <span>Variants</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-views-label\">\n",
       " <span>Views</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-cactions-label\">\n",
       " <span>More</span>\n",
       " </h3>,\n",
       " <h3>\n",
       " <label for=\"searchInput\">Search</label>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-navigation-label\">\n",
       " <span>Navigation</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-interaction-label\">\n",
       " <span>Contribute</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-tb-label\">\n",
       " <span>Tools</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-coll-print_export-label\">\n",
       " <span>Print/export</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\">\n",
       " <span>In other projects</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-lang-label\">\n",
       " <span>Languages</span>\n",
       " </h3>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function Definition\n",
    "def header_tags(url):\n",
    "    a = requests.get(url)\n",
    "    src = a.content\n",
    "    soup = BeautifulSoup(src,'html.parser')\n",
    "    return soup.find_all([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\"])\n",
    "\n",
    "# Calling Function\n",
    "header_tags('https://en.wikipedia.org/wiki/Main_Page')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and save it in form of a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    names   years  ratings\n",
      "0                The Shawshank Redemption  (1994)      9.2\n",
      "1                           The Godfather  (1972)      9.1\n",
      "2                  The Godfather: Part II  (1974)      9.0\n",
      "3                         The Dark Knight  (2008)      9.0\n",
      "4                            12 Angry Men  (1957)      8.9\n",
      "..                                    ...     ...      ...\n",
      "95                           Idi i smotri  (1985)      8.3\n",
      "96                    Requiem for a Dream  (2000)      8.3\n",
      "97                    Singin' in the Rain  (1952)      8.3\n",
      "98                     North by Northwest  (1959)      8.3\n",
      "99  Eternal Sunshine of the Spotless Mind  (2004)      8.3\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def IMDB_top_100(url):\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.content,'html.parser')\n",
    "    name=[]\n",
    "    year=[]\n",
    "    rating=[]\n",
    "    for i in soup.find_all('img'):\n",
    "        name.append(i.attrs['alt'])\n",
    "    for i in list(soup.find_all('span',attrs={\"secondaryInfo\"})):\n",
    "        year.append(i.text)\n",
    "    for i in soup.find_all('strong'):\n",
    "        rating.append(float(i.text))\n",
    "    df=pd.DataFrame({'names':name[:100],\n",
    "                     'years':year[:100],\n",
    "                     'ratings':rating[:100]})\n",
    "    print(df)\n",
    "    df.to_csv('IMDB_top_100.csv', index = False)\n",
    "\n",
    "# Calling Function\n",
    "IMDB_top_100(\"https://www.imdb.com/chart/top/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and save it in form of a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                names   years  ratings\n",
      "0                             Nayakan  (1987)      8.5\n",
      "1                   Pariyerum Perumal  (2018)      8.5\n",
      "2                          Anbe Sivam  (2003)      8.5\n",
      "3                   C/o Kancharapalem  (2018)      8.5\n",
      "4                             Golmaal  (1979)      8.5\n",
      "..                                ...     ...      ...\n",
      "95                    Andaz Apna Apna  (1994)      8.1\n",
      "96  Lagaan: Once Upon a Time in India  (2001)      8.1\n",
      "97                            Kahaani  (2012)      8.1\n",
      "98           Uri: The Surgical Strike  (2018)      8.1\n",
      "99                                 PK  (2014)      8.1\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def Indian_IMDB_top_100(url):\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.content,'html.parser')\n",
    "    name=[]\n",
    "    year=[]\n",
    "    rating=[]\n",
    "    for i in soup.find_all('img'):\n",
    "        name.append(i.attrs['alt'])\n",
    "    for i in list(soup.find_all('span',attrs={\"secondaryInfo\"})):\n",
    "        year.append(i.text)\n",
    "    for i in soup.find_all('strong'):\n",
    "        rating.append(float(i.text))\n",
    "    df=pd.DataFrame({'names':name[:100],\n",
    "                     'years':year[:100],\n",
    "                     'ratings':rating[:100]})\n",
    "    print(df)\n",
    "    df.to_csv('indian_IMDB_top_100.csv', index = False)\n",
    "\n",
    "# Calling Function\n",
    "Indian_IMDB_top_100(\"https://www.imdb.com/india/top-rated-indian-movies/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4. Write a python program to scrap book name, author name, genre and book review of any 5 books from ‘www.bookpage.com’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Being Clem</td>\n",
       "      <td>Lesa Cline-Ransome</td>\n",
       "      <td>Children's / Middle Grade</td>\n",
       "      <td>On the very first page of Lesa Cline-Ransome’s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>★ How to Find Your Way in the Dark</td>\n",
       "      <td>Derek B. Miller</td>\n",
       "      <td>Fiction / Coming of Age</td>\n",
       "      <td>Prepare for surprises galore in How to Find Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hold Fast Through the Fire</td>\n",
       "      <td>K.B. Wagers</td>\n",
       "      <td>Science Fiction &amp; Fantasy / Science Fiction</td>\n",
       "      <td>Looking for a quick bit of adrenaline, a spot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Good Day for Chardonnay</td>\n",
       "      <td>Darynda Jones</td>\n",
       "      <td>Mystery &amp; Suspense / Mystery</td>\n",
       "      <td>Readers who enjoy murder mysteries with lots o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All’s Well</td>\n",
       "      <td>Mona Awad</td>\n",
       "      <td>Fiction / Literary Fiction</td>\n",
       "      <td>Miranda Fitch, the protagonist of Mona Awad’s ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Book Name              Author  \\\n",
       "0                          Being Clem  Lesa Cline-Ransome   \n",
       "1  ★ How to Find Your Way in the Dark     Derek B. Miller   \n",
       "2          Hold Fast Through the Fire         K.B. Wagers   \n",
       "3           A Good Day for Chardonnay       Darynda Jones   \n",
       "4                          All’s Well           Mona Awad   \n",
       "\n",
       "                                         Genre  \\\n",
       "0                    Children's / Middle Grade   \n",
       "1                      Fiction / Coming of Age   \n",
       "2  Science Fiction & Fantasy / Science Fiction   \n",
       "3                 Mystery & Suspense / Mystery   \n",
       "4                   Fiction / Literary Fiction   \n",
       "\n",
       "                                              Review  \n",
       "0  On the very first page of Lesa Cline-Ransome’s...  \n",
       "1  Prepare for surprises galore in How to Find Yo...  \n",
       "2  Looking for a quick bit of adrenaline, a spot ...  \n",
       "3  Readers who enjoy murder mysteries with lots o...  \n",
       "4  Miranda Fitch, the protagonist of Mona Awad’s ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function Definition\n",
    "def bookpage():\n",
    "    response = requests.get('https://bookpage.com/reviews/')\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    url_tags = soup.find_all('div', attrs = {'class': 'row-fluid article-row'})\n",
    "    urls = [i.find('h4').find_all('a')[0]['href'] for i in url_tags[0:5]]\n",
    "    book_dict = {}\n",
    "    book_dict[\"Book Name\"] = []\n",
    "    book_dict[\"Author\"] = []\n",
    "    book_dict[\"Genre\"] = []\n",
    "    book_dict[\"Review\"] = []\n",
    "    for url in urls:\n",
    "        book = requests.get('https://www.bookpage.com'+url)\n",
    "        soup = BeautifulSoup(book.content, 'html.parser')\n",
    "        book_dict[\"Book Name\"].append(soup.find('h1').text.replace('\\n',''))\n",
    "        book_dict[\"Author\"].append(soup.find('h4').text.replace('\\n',''))\n",
    "        book_dict[\"Genre\"].append(soup.find('p', attrs = {'class':'genre-links'}).text.replace('\\n',''))\n",
    "        book_dict[\"Review\"].append(soup.find('div', attrs = {'class':'article-body'}).text.replace('\\n',''))\n",
    "    book_df = pd.DataFrame.from_dict(book_dict)\n",
    "    book_df.to_csv('Book Reviews.csv', index = False)\n",
    "    return book_df\n",
    "\n",
    "# Calling Function\n",
    "bookpage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.                                 \n",
    "ii) Top 10 ODI Batsmen in men along with the records of their team and rating.                                             \n",
    "iii) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "### Solution:\n",
    "i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Team Match Points\n",
      "0   New Zealand    17  2,054\n",
      "1       England    32  3,793\n",
      "2     Australia    27  3,109\n",
      "3         India    32  3,624\n",
      "4  South Africa    22  2,267\n",
      "5      Pakistan    27  2,524\n",
      "6    Bangladesh    29  2,639\n",
      "7   West Indies    29  2,458\n",
      "8     Sri Lanka    29  2,303\n",
      "9   Afghanistan    17  1,054\n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def Top_10_ODI_team(url):\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.content,'html.parser')\n",
    "    team=[]\n",
    "    match=[]\n",
    "    rating=[]\n",
    "    for i in soup.find_all('span',attrs={'u-hide-phablet'}):\n",
    "        team.append(i.text)\n",
    "    match.append(soup.find('td',attrs={'rankings-block__banner--matches'}).text)\n",
    "    rating.append(soup.find('td',attrs={'rankings-block__banner--points'}).text)\n",
    "    count=0\n",
    "    for i in list(soup.find_all('td',attrs={'table-body__cell u-center-text'}))[:18]:\n",
    "        if count%2==0:\n",
    "            match.append(i.text)\n",
    "        else:\n",
    "            rating.append(i.text)\n",
    "        count+=1\n",
    "    df=pd.DataFrame({'Team':team[:10],\n",
    "                     'Match':match,\n",
    "                     'Points':rating})\n",
    "    df.to_csv('top_10_odi_teams_men.csv', index = False)\n",
    "    print(df)\n",
    "\n",
    "# Calling Function\n",
    "Top_10_ODI_team('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Top 10 ODI Batsmen in men along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Name       Team points\n",
      "0       Babar Azam  \\n\\nPAK\\n    873\n",
      "1      Virat Kohli        IND    844\n",
      "2     Rohit Sharma        IND    813\n",
      "3      Ross Taylor         NZ    801\n",
      "4      Aaron Finch        AUS    779\n",
      "5   Jonny Bairstow        ENG    775\n",
      "6     David Warner        AUS    762\n",
      "7  Quinton de Kock         SA    758\n",
      "8        Shai Hope         WI    758\n",
      "9  Kane Williamson         NZ    754\n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def Top_10_ODI_batsman(url):\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.content,'html.parser')\n",
    "    name=[]\n",
    "    team=[]\n",
    "    point=[]\n",
    "    name.append(soup.find('div',attrs={\"rankings-block__banner--name-large\"}).text)\n",
    "    for i in list(soup.find_all('td',attrs={'table-body__cell rankings-table__name name'}))[:9]:\n",
    "        name.append(i.text.replace('\\n',''))\n",
    "    team.append(soup.find('div',attrs={\"rankings-block__banner--nationality\"}).text)\n",
    "    for i in list(soup.find_all('td',attrs={'table-body__cell nationality-logo rankings-table__team'}))[:9]:\n",
    "        team.append(i.text.replace('\\n',''))\n",
    "    point.append(soup.find('div',attrs={\"rankings-block__banner--rating\"}).text)\n",
    "    for i in list(soup.find_all('td',attrs={'table-body__cell rating'}))[:9]:\n",
    "        point.append(i.text)\n",
    "    df=pd.DataFrame({'Name': name,\n",
    "                     'Team':team,\n",
    "                     'points':point})\n",
    "    df.to_csv('top_10_odi_batsman.csv', index = False)\n",
    "    print(df)\n",
    "\n",
    "# Calling Function\n",
    "Top_10_ODI_batsman(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Name      Team points\n",
      "0       Trent Boult  \\n\\nNZ\\n    737\n",
      "1    Josh Hazlewood       AUS    709\n",
      "2  Mujeeb Ur Rahman       AFG    708\n",
      "3      Chris Woakes       ENG    700\n",
      "4      Mehedi Hasan       BAN    692\n",
      "5        Matt Henry        NZ    691\n",
      "6    Jasprit Bumrah       IND    679\n",
      "7    Mitchell Starc       AUS    652\n",
      "8   Shakib Al Hasan       BAN    650\n",
      "9     Kagiso Rabada        SA    648\n"
     ]
    }
   ],
   "source": [
    "def Top_10_ODI_bowler(url):\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.content,'html.parser')\n",
    "    name=[]\n",
    "    team=[]\n",
    "    point=[]\n",
    "    name.append(soup.find('div',attrs={\"rankings-block__banner--name-large\"}).text)\n",
    "    for i in list(soup.find_all('td',attrs={'table-body__cell rankings-table__name name'}))[:9]:\n",
    "        name.append(i.text.replace('\\n',''))\n",
    "    team.append(soup.find('div',attrs={\"rankings-block__banner--nationality\"}).text)\n",
    "    for i in list(soup.find_all('td',attrs={'table-body__cell nationality-logo rankings-table__team'}))[:9]:\n",
    "        team.append(i.text.replace('\\n',''))\n",
    "    point.append(soup.find('div',attrs={\"rankings-block__banner--rating\"}).text)\n",
    "    for i in list(soup.find_all('td',attrs={'table-body__cell rating'}))[:9]:\n",
    "        point.append(i.text)\n",
    "    df=pd.DataFrame({'Name': name,\n",
    "                     'Team':team,\n",
    "                     'points':point})\n",
    "    df.to_csv('top_10_odi_bowler.csv', index = False)\n",
    "    print(df)\n",
    "\n",
    "# Calling Function\n",
    "Top_10_ODI_bowler(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.                                  \n",
    "ii) Top 10 women’s ODI players along with the records of their team and rating.                                                \n",
    "iii) Top 10 women’s ODI all-rounder along with the records of their team and rating. \n",
    "\n",
    "#### Solutions:\n",
    "i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Team Match Points\n",
      "0     Australia    18  2,955\n",
      "1       England    20  2,370\n",
      "2  South Africa    24  2,828\n",
      "3         India    23  2,535\n",
      "4   New Zealand    21  1,947\n",
      "5   West Indies    17  1,427\n",
      "6      Pakistan    20  1,496\n",
      "7    Bangladesh     5    306\n",
      "8     Sri Lanka    11    519\n",
      "9       Ireland     2     25\n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def Top_10_Women_ODI_team(url):\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.content,'html.parser')\n",
    "    team=[]\n",
    "    match=[]\n",
    "    rating=[]\n",
    "    for i in soup.find_all('span',attrs={'u-hide-phablet'}):\n",
    "        team.append(i.text)\n",
    "    match.append(soup.find('td',attrs={'rankings-block__banner--matches'}).text)\n",
    "    rating.append(soup.find('td',attrs={'rankings-block__banner--points'}).text)\n",
    "    count=0\n",
    "    for i in list(soup.find_all('td',attrs={'table-body__cell u-center-text'}))[:18]:\n",
    "        if count%2==0:\n",
    "            match.append(i.text)\n",
    "        else:\n",
    "            rating.append(i.text)\n",
    "        count+=1\n",
    "    df=pd.DataFrame({'Team':team[:10],\n",
    "                     'Match':match,\n",
    "                     'Points':rating})\n",
    "    df.to_csv('top_10_women_odi_teams.csv', index = False)\n",
    "    print(df)\n",
    "\n",
    "# Calling Function\n",
    "Top_10_Women_ODI_team('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Top 10 women’s ODI players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Name       Team points\n",
      "0        Mithali Raj  \\n\\nIND\\n    762\n",
      "1        Lizelle Lee         SA    758\n",
      "2       Alyssa Healy        AUS    756\n",
      "3     Tammy Beaumont        ENG    754\n",
      "4    Stafanie Taylor         WI    736\n",
      "5        Meg Lanning        AUS    723\n",
      "6  Amy Satterthwaite         NZ    715\n",
      "7     Natalie Sciver        ENG    706\n",
      "8    Smriti Mandhana        IND    701\n",
      "9    Laura Wolvaardt         SA    683\n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def Top_10_Women_ODI_player(url):\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.content,'html.parser')\n",
    "    name=[]\n",
    "    team=[]\n",
    "    point=[]\n",
    "    name.append(soup.find('div',attrs={\"rankings-block__banner--name-large\"}).text)\n",
    "    for i in list(soup.find_all('td',attrs={'table-body__cell rankings-table__name name'}))[:9]:\n",
    "        name.append(i.text.replace('\\n',''))\n",
    "    team.append(soup.find('div',attrs={\"rankings-block__banner--nationality\"}).text)\n",
    "    for i in list(soup.find_all('td',attrs={'table-body__cell nationality-logo rankings-table__team'}))[:9]:\n",
    "        team.append(i.text.replace('\\n',''))\n",
    "    point.append(soup.find('div',attrs={\"rankings-block__banner--rating\"}).text)\n",
    "    for i in list(soup.find_all('td',attrs={'table-body__cell rating'}))[:9]:\n",
    "        point.append(i.text)\n",
    "    df=pd.DataFrame({'Name': name,\n",
    "                     'Team':team,\n",
    "                     'points':point})\n",
    "    df.to_csv('top_10_women_odi_player.csv', index = False)\n",
    "    print(df)\n",
    "\n",
    "# Calling Function\n",
    "Top_10_Women_ODI_player(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Name      Team points\n",
      "0    Marizanne Kapp  \\n\\nSA\\n    418\n",
      "1      Ellyse Perry       AUS    418\n",
      "2   Stafanie Taylor        WI    394\n",
      "3    Natalie Sciver       ENG    365\n",
      "4     Deepti Sharma       IND    331\n",
      "5     Jess Jonassen       AUS    307\n",
      "6  Ashleigh Gardner       AUS    252\n",
      "7  Dane van Niekerk        SA    243\n",
      "8     Sophie Devine        NZ    242\n",
      "9   Katherine Brunt       ENG    239\n"
     ]
    }
   ],
   "source": [
    "#Function Definition\n",
    "def Top_10_Women_ODI_Allrounder(url):\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.content,'html.parser')\n",
    "    name=[]\n",
    "    team=[]\n",
    "    point=[]\n",
    "    name.append(soup.find('div',attrs={\"rankings-block__banner--name-large\"}).text)\n",
    "    for i in list(soup.find_all('td',attrs={'table-body__cell rankings-table__name name'}))[:9]:\n",
    "        name.append(i.text.replace('\\n',''))\n",
    "    team.append(soup.find('div',attrs={\"rankings-block__banner--nationality\"}).text)\n",
    "    for i in list(soup.find_all('td',attrs={'table-body__cell nationality-logo rankings-table__team'}))[:9]:\n",
    "        team.append(i.text.replace('\\n',''))\n",
    "    point.append(soup.find('div',attrs={\"rankings-block__banner--rating\"}).text)\n",
    "    for i in list(soup.find_all('td',attrs={'table-body__cell rating'}))[:9]:\n",
    "        point.append(i.text)\n",
    "    df=pd.DataFrame({'Name': name,\n",
    "                     'Team':team,\n",
    "                     'points':point})\n",
    "    df.to_csv('top_10_women_odi_allrounder.csv', index = False)\n",
    "    print(df)\n",
    "\n",
    "# Calling function\n",
    "Top_10_Women_ODI_Allrounder(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7. Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Name      Price  \\\n",
      "0    Redmi 9A (Nature Green, 2GB RAM, 32GB Storage)...   8,499.00   \n",
      "1    Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage) | 2....  10,999.00   \n",
      "2    Oppo A31 (Fantasy White, 6GB RAM, 128GB Storag...   2,490.00   \n",
      "3    Samsung Galaxy M11 (Black, 4GB RAM, 64GB Stora...  14,999.00   \n",
      "4    Redmi Note 9 (Pebble Grey, 4GB RAM 64GB Storag...  14,999.00   \n",
      "..                                                 ...        ...   \n",
      "120  Nokia 225 4G Dual SIM Feature Phone with Long ...   4,399.00   \n",
      "121                           Nokia 150 (2020) (Black)   2,799.00   \n",
      "122  Samsung Galaxy M11 (Violet, 4GB RAM, 64GB Stor...  14,999.00   \n",
      "123  Maplin Ismart I1 Reno (2 GB 16 GB) 5.0 inch To...   9,999.00   \n",
      "124  Redmi 9A (Sea Blue 2GB RAM 32GB Storage) | 2GH...   8,499.00   \n",
      "\n",
      "                 Rating                                         Image_link  \n",
      "0    4.2 out of 5 stars  https://images-na.ssl-images-amazon.com/images...  \n",
      "1    4.2 out of 5 stars  https://images-na.ssl-images-amazon.com/images...  \n",
      "2    4.2 out of 5 stars  https://images-na.ssl-images-amazon.com/images...  \n",
      "3    4.1 out of 5 stars  https://images-eu.ssl-images-amazon.com/images...  \n",
      "4    4.3 out of 5 stars  https://images-na.ssl-images-amazon.com/images...  \n",
      "..                  ...                                                ...  \n",
      "120  3.5 out of 5 stars  https://images-na.ssl-images-amazon.com/images...  \n",
      "121  3.9 out of 5 stars  https://images-na.ssl-images-amazon.com/images...  \n",
      "122  4.2 out of 5 stars  https://images-eu.ssl-images-amazon.com/images...  \n",
      "123  5.0 out of 5 stars  https://images-na.ssl-images-amazon.com/images...  \n",
      "124  4.2 out of 5 stars  https://images-na.ssl-images-amazon.com/images...  \n",
      "\n",
      "[125 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def amazon_mob(url):\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\HP\\Desktop\\Data Trained\\Flip Robo\\chromedriver.exe\")\n",
    "    start_page=0\n",
    "    end_page=4\n",
    "    urls = []\n",
    "    name=[]\n",
    "    price=[]\n",
    "    image=[]\n",
    "    rating=[]\n",
    "    #loop to fetch urls of each mobile till page 5\n",
    "    for page in range(start_page,end_page+1):\n",
    "        driver.get(url)\n",
    "        soup= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        prod_urls = soup.find_all('a', attrs ={'class':'a-link-normal a-text-normal'})\n",
    "        for prod in prod_urls:\n",
    "            urls.append('https://www.amazon.in'+prod.get('href'))\n",
    "    \n",
    "    #loop to scrap required details from each mobile page\n",
    "    for url in urls:\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        n = soup.find('h1',attrs={'id':'title'})\n",
    "        if n is not None:\n",
    "            name.append(n.find('span').text.replace('\\n',''))\n",
    "        else:\n",
    "            name.append('-')\n",
    "        rat = soup.find('div', attrs = {'id':'averageCustomerReviews'})\n",
    "        if rat is not None:\n",
    "            rating.append(rat.find('i').find('span').text)\n",
    "        else:\n",
    "            rating.append('-')\n",
    "        p = soup.find('span', attrs = {'class':'a-size-medium a-color-price priceBlockDealPriceString'})\n",
    "        if p is not None:\n",
    "            price.append(p.text[2:])\n",
    "        else:\n",
    "            p = soup.find('div', attrs = {'id':'price'})\n",
    "            if p is not None:\n",
    "                price.append(p.find('span').text[2:])\n",
    "            else:\n",
    "                price.append('-')\n",
    "        img = soup.find('div', attrs = {'class':'imgTagWrapper'})\n",
    "        if img is not None:\n",
    "            image.append(img.find('img').get('src'))\n",
    "        else:\n",
    "            image.append('-')\n",
    "    mob_df = df=pd.DataFrame({'Name':name,\n",
    "                              'Price':price,\n",
    "                              'Rating':rating,\n",
    "                              'Image_link':image})\n",
    "    print(mob_df)\n",
    "    mob_df.to_csv('Amazon Mobiles.csv', index = False)\n",
    "    \n",
    "    \n",
    "# Calling Function\n",
    "amazon_mob('https://www.amazon.in/s?k=mobile+phones+under+20000&rh=n%3A1389432031&dc&qid=1604132579&rnid=3576079031&ref=sr_nr_n_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8. Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city. The data should include period, short description, temperature and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          period                         short_description  temperature  \\\n",
      "0          Today    Partly Sunnythen MostlySunny andBreezy  High: 71 °F   \n",
      "1        Tonight  Mostly Cloudyand Breezythen MostlyCloudy   Low: 57 °F   \n",
      "2       Thursday    Partly Sunnythen MostlySunny andBreezy  High: 70 °F   \n",
      "3  ThursdayNight  Partly Cloudyand Breezythen MostlyCloudy   Low: 56 °F   \n",
      "4         Friday          Mostly Sunnythen Sunnyand Breezy  High: 69 °F   \n",
      "5    FridayNight                             Mostly Cloudy   Low: 56 °F   \n",
      "6       Saturday                              Partly Sunny  High: 67 °F   \n",
      "7  SaturdayNight                             Mostly Cloudy   Low: 56 °F   \n",
      "8         Sunday                              Mostly Sunny  High: 68 °F   \n",
      "\n",
      "                                         description  \n",
      "0  Mostly sunny, with a high near 71. Breezy, wit...  \n",
      "1  Mostly cloudy, with a low around 57. Breezy, w...  \n",
      "2  Mostly cloudy, then gradually becoming sunny, ...  \n",
      "3  Partly cloudy, with a low around 56. Breezy, w...  \n",
      "4  Mostly sunny, with a high near 69. Breezy, wit...  \n",
      "5               Mostly cloudy, with a low around 56.  \n",
      "6                 Partly sunny, with a high near 67.  \n",
      "7               Mostly cloudy, with a low around 56.  \n",
      "8                 Mostly sunny, with a high near 68.  \n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def weather(url):\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.content,'html.parser')\n",
    "    period=[]\n",
    "    short_desc=[]\n",
    "    temp=[]\n",
    "    desc=[]\n",
    "    for i in soup.find_all('p',attrs={'period-name'}):\n",
    "        period.append(i.text)\n",
    "    for i in soup.find_all('p',attrs={'short-desc'}):\n",
    "        short_desc.append(i.text)\n",
    "    for i in soup.find_all('p',attrs={'short-desc'}):\n",
    "        if i.next_sibling is not None:\n",
    "            temp.append(i.next_sibling.text)\n",
    "        else:\n",
    "            temp.append(' ')\n",
    "    for i in soup.find_all('div',attrs={\"col-sm-10 forecast-text\"}):\n",
    "        desc.append(i.text)\n",
    "    df=pd.DataFrame({\"period\":period,\n",
    "                     \"short_description\":short_desc,\n",
    "                     \"temperature\":temp,\n",
    "                     \"description\":desc[:9]})\n",
    "    df.to_csv('Extended_forecast.csv')\n",
    "    print(df)\n",
    "\n",
    "# Calling Function\n",
    "weather(\"https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.X6Pyxe3hWMo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q9. Write a python program to scrape ‘software developer’ job listings from ‘Monster.com’. It should include all the jobs listed for the next 5 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Job_Names  \\\n",
      "0        Data Science sponsored Tech Mahindra Limited   \n",
      "1                                  Software Developer   \n",
      "2                          Software Developer Trainee   \n",
      "3                           Software Developer - Java   \n",
      "4   Software Developer - Tech Mahindra Business Se...   \n",
      "5               EDCI - Engineering Software Developer   \n",
      "6                     SOFTWARE DEVELOPER JAVA /PYTHON   \n",
      "7   Consulting Firm hiring Experienced Semi-CA, CM...   \n",
      "8                     Python Developer Java Developer   \n",
      "9                    NEED Software Developer /DOT NET   \n",
      "10                                  ReactJS Developer   \n",
      "11  Core Java Developer for Software Company in Pu...   \n",
      "12                                  Dot Net Developer   \n",
      "13                           Web Application DESIGNER   \n",
      "14                                  ASP.NET Developer   \n",
      "15                               Salesforce Developer   \n",
      "16                                     Java Developer   \n",
      "17                           Java Developer Core Java   \n",
      "18                   React JS Developer @ Accion Labs   \n",
      "19  .NET Core Developer (microservices Exp for at ...   \n",
      "20                                   Senior Developer   \n",
      "21              Application Management Senior Analyst   \n",
      "22                               Sharepoint Developer   \n",
      "23  Urgent Requirement For Software Engineer in Ca...   \n",
      "24               Software Developer Software Engineer   \n",
      "25                                Datastage Developer   \n",
      "26  \" ReactJS Developer \"- Urgently required for A...   \n",
      "27                                         MERN STACK   \n",
      "28                          Java Full Stack Developer   \n",
      "29                                      Php developer   \n",
      "30  Software Developer,Required in CANADA & AUSTRALIA   \n",
      "31  React Native Developer All Levels (Sr.,Mid,Jr....   \n",
      "32  Sr. Software Engineer PHP Developer. Laravel, ...   \n",
      "33                               OBIEE/ODI Consultant   \n",
      "34                                  Hot Vacancies for   \n",
      "35                                 software developer   \n",
      "36                               Full Stack Developer   \n",
      "37                                 Software Developer   \n",
      "38                                Mainframe Developer   \n",
      "39                           Full Stack Web Developer   \n",
      "\n",
      "                                         Company  \\\n",
      "0                                                  \n",
      "1             Prosares Solutions Private Limited   \n",
      "2                             software engineers   \n",
      "3                          Freelancer D. Aravind   \n",
      "4        Tech Mahindra Business Services Limited   \n",
      "5   Le Human Resources Solutions Private Limited   \n",
      "6                             S H Career Company   \n",
      "7                                                  \n",
      "8                                Software Tester   \n",
      "9                             S H Career Company   \n",
      "10                                     Onpassive   \n",
      "11                          Namura Hr Consulting   \n",
      "12             Supernal Infotech Private Limited   \n",
      "13                       Easeprint Solutions.com   \n",
      "14                       Easeprint Solutions.com   \n",
      "15     IPS Vantage Tech Services Private Limited   \n",
      "16     IPS Vantage Tech Services Private Limited   \n",
      "17                       Tresbien Hr Consultancy   \n",
      "18             Accion Labs India Private Limited   \n",
      "19             Accion Labs India Private Limited   \n",
      "20      Teamroll Global Services Private Limited   \n",
      "21                      Ideslabs Private Limited   \n",
      "22            Xytiq Technologies Private Limited   \n",
      "23                    Cloud Visa Immigration LLP   \n",
      "24                                 Skill Ventory   \n",
      "25                  Itmc Systems Private Limited   \n",
      "26                           Free Lancer S Divya   \n",
      "27                     Change Leaders Consulting   \n",
      "28                 MNR Solutions Private Limited   \n",
      "29                     Company Name Confidential   \n",
      "30            Nobreza Consulting Private Limited   \n",
      "31     Techno Compass Consulting Private Limited   \n",
      "32     Elite Corporate Solutions Private Limited   \n",
      "33                  Itmc Systems Private Limited   \n",
      "34                             Dot net Developer   \n",
      "35   Orcapod Consulting Services Private Limited   \n",
      "36                     Xodus Consulting Services   \n",
      "37               Pleco Migration Private Limited   \n",
      "38                Bct Consulting Private Limited   \n",
      "39                          MABZONE IT SOLUTIONS   \n",
      "\n",
      "                                             location  \\\n",
      "0                                   Hyderabad / Se...   \n",
      "1                                              Mumbai   \n",
      "2                                              Mysore   \n",
      "3                                   Gurgaon / Guru...   \n",
      "4                                         Mumbai City   \n",
      "5                                             Chennai   \n",
      "6                                   Gurgaon / Guru...   \n",
      "7                                   Bengaluru / Ba...   \n",
      "8                                   Bengaluru / Ba...   \n",
      "9                                   Gurgaon / Guru...   \n",
      "10                                  Hyderabad / Se...   \n",
      "11                                               Pune   \n",
      "12                                  Bengaluru / Ba...   \n",
      "13                                          Faridabad   \n",
      "14                                          Faridabad   \n",
      "15                                               Pune   \n",
      "16                                               Pune   \n",
      "17                                  Bengaluru / Ba...   \n",
      "18                                  Bengaluru / Ba...   \n",
      "19                                             Mumbai   \n",
      "20                                  Bengaluru / Ba...   \n",
      "21                                  Bengaluru / Ba...   \n",
      "22                                  Bengaluru / Ba...   \n",
      "23                                  Australia, Canada   \n",
      "24                                               Pune   \n",
      "25                                  Hyderabad / Se...   \n",
      "26                                          Ahmedabad   \n",
      "27                                  Bengaluru / Ba...   \n",
      "28                                  Bengaluru / Ba...   \n",
      "29                                  Cochin / Kochi...   \n",
      "30                                  Australia, Canada   \n",
      "31                                    Chennai, Mumbai   \n",
      "32                                  Delhi, Gurgaon...   \n",
      "33                                             Remote   \n",
      "34                                  Hyderabad / Se...   \n",
      "35                                  Bengaluru / Ba...   \n",
      "36                                            Chennai   \n",
      "37                                  Canada, Hong Kong   \n",
      "38                                  Hyderabad / Se...   \n",
      "39                                             Mohali   \n",
      "\n",
      "                                    Experience  \\\n",
      "0                                 5-10 Years     \n",
      "1                                  1-5 Years     \n",
      "2                                  0-1 Years     \n",
      "3                                  4-8 Years     \n",
      "4                                  1-6 Years     \n",
      "5                                  3-5 Years     \n",
      "6                                  0-2 Years     \n",
      "7                                  1-5 Years     \n",
      "8                                    Fresher     \n",
      "9                                  0-2 Years     \n",
      "10                                 3-8 Years     \n",
      "11                                 2-4 Years     \n",
      "12                                 5-8 Years     \n",
      "13                                 1-2 Years     \n",
      "14                                 1-3 Years     \n",
      "15                                 5-8 Years     \n",
      "16                                4-10 Years     \n",
      "17                                 2-4 Years     \n",
      "18                                 4-8 Years     \n",
      "19                                 4-8 Years     \n",
      "20                                 5-9 Years     \n",
      "21                                5-11 Years     \n",
      "22                                 3-8 Years     \n",
      "23                                 4-9 Years     \n",
      "24                                 4-8 Years     \n",
      "25                                8-10 Years     \n",
      "26                                2-12 Years     \n",
      "27                                3-10 Years     \n",
      "28                                 4-8 Years     \n",
      "29                                 3-8 Years     \n",
      "30                                 3-8 Years     \n",
      "31                                 2-7 Years     \n",
      "32                                 3-6 Years     \n",
      "33                                 5-8 Years     \n",
      "34                                7-15 Years     \n",
      "35                                 4-5 Years     \n",
      "36                                 4-7 Years     \n",
      "37                                 2-7 Years     \n",
      "38                                5-10 Years     \n",
      "39                                 3-5 Years     \n",
      "\n",
      "                                               Salary  \n",
      "0                                       Not Specified  \n",
      "1                                       Not Specified  \n",
      "2                                   1,50,000-4,00,...  \n",
      "3                                   12,00,000-18,0...  \n",
      "4                                   0-20,000 INR P...  \n",
      "5                                       Not Specified  \n",
      "6                                   4,90,000-10,10...  \n",
      "7                                       Not Specified  \n",
      "8                                   3,20,000-4,50,...  \n",
      "9                                   4,80,000-8,60,...  \n",
      "10                                      Not Specified  \n",
      "11                                  6,00,000-9,00,...  \n",
      "12                                  10,00,000-18,0...  \n",
      "13                                  2,00,000-3,00,...  \n",
      "14                                  2,00,000-5,00,...  \n",
      "15                                      Not Specified  \n",
      "16                                  10,000-14,50,0...  \n",
      "17                                  5,00,000-6,50,...  \n",
      "18                                      Not Specified  \n",
      "19                                      Not Specified  \n",
      "20                                  4,00,000-15,00...  \n",
      "21                                      Not Specified  \n",
      "22                                      Not Specified  \n",
      "23                                  40,50,000-60,0...  \n",
      "24                                  9,00,000-16,00...  \n",
      "25                                      Not Specified  \n",
      "26                                      Not Specified  \n",
      "27                                      Not Specified  \n",
      "28                                  4,00,000-16,00...  \n",
      "29                                      Not Specified  \n",
      "30                                  40,00,000-55,0...  \n",
      "31                                      Not Specified  \n",
      "32                                  6,00,000-9,00,...  \n",
      "33                                  6,00,000-9,00,...  \n",
      "34                                      Not Specified  \n",
      "35                                      Not Specified  \n",
      "36                                      Not Specified  \n",
      "37                                  25,00,000-45,0...  \n",
      "38                                      Not Specified  \n",
      "39                                  3,00,000-6,00,...  \n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def soft_dev(url):\n",
    "    driver=webdriver.Chrome(r\"D:\\DATA_SCIENCE\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    start_page=0\n",
    "    end_page=4\n",
    "    urls=[]\n",
    "    job_names=[]\n",
    "    company=[]\n",
    "    location=[]\n",
    "    experience=[]\n",
    "    salary=[]\n",
    "    for page in range(start_page,end_page+1):\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        jobs=soup.find_all('div', attrs ={'class':'job-tittle'})\n",
    "        for job in jobs:\n",
    "            l=job.text.split('\\n')\n",
    "            job_names.append(l[0].split('  ')[0])\n",
    "            company.append(l[0].split('  ')[1])\n",
    "            location.append(l[1])\n",
    "            experience.append(l[2])\n",
    "            salary.append(l[3])\n",
    "        try:\n",
    "    \n",
    "            nxt_button=driver.find_element_by_xpath(\"//button[@class='btn-next-prev btn-next']\")\n",
    "            if nxt_button.text=='Next':\n",
    "                nxt_button.click()\n",
    "                time.sleep(5)\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "            \n",
    "\n",
    "    job_df=pd.DataFrame({'Job_Names':job_names,\n",
    "                         'Company':company,\n",
    "                         'location':location,\n",
    "                         'Experience':experience,\n",
    "                         'Salary':salary})\n",
    "    job_df.to_csv('Software Developer_Monster', index = False)\n",
    "    print(job_df)\n",
    "\n",
    "# Calling Function\n",
    "soft_dev(\"https://www.monsterindia.com/srp/results?query=software%20developer&searchId=1eef9a54-8213-4bcf-9ef7-8605ec8202c5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q10. Write a python program to scrape ‘data scientist’ job listings for location ‘New Delhi’ from ‘Monster.com’. It should include all the jobs listed for the next 5 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Job_Names  \\\n",
      "0   Data Entry Job l Work From Home l Freelancers ...   \n",
      "1                           Data Entry Work From Home   \n",
      "2   Work From Home, Data Entry Jobs, Part Time Job...   \n",
      "3   Online Data Entry, Work From Home Jobs, Part T...   \n",
      "4   Online Data Entry Jobs, Work From Home, Data E...   \n",
      "5   Work From Home Jobs, Data Entry, Part Time Job...   \n",
      "6   Typing Jobs, Online Data Entry Jobs, Work From...   \n",
      "7   Online Data Entry Jobs, Work From Home, Part T...   \n",
      "8   Data Entry Jobs, Part Time Jobs, Home Based, W...   \n",
      "9   Online Data Entry Jobs, Work From Home, Part T...   \n",
      "10               Computer Operator & Office Assistant   \n",
      "11               Computer operator Data Entry Backend   \n",
      "12                                         Data Entry   \n",
      "13               Marketing Executive (based in India)   \n",
      "14  HIRING FOR RESEARCH ANALYST ROLE_SALARY UPTO 5...   \n",
      "15  Visa Documentation Executive Required In Netaj...   \n",
      "16                                              Audit   \n",
      "17   Oracle Cloud HCM Functional Consultant - Core HR   \n",
      "18                                         Accountant   \n",
      "19                                  SAP SD Consultant   \n",
      "20                               Sales Representative   \n",
      "21                           EDQ Technical Specialist   \n",
      "22                                      Store Manager   \n",
      "23                            Head Finance & Accounts   \n",
      "24      Cyber Security Sales Manager - Cymune (Locuz)   \n",
      "25                                        MEP Manager   \n",
      "26     Sr . Manager ( Performance & Growth marketing)   \n",
      "27                                Civil Site Engineer   \n",
      "28                        Senior Engineer- Electrical   \n",
      "29                                  Senior HR Manager   \n",
      "30             sal.30k ctc/us voice travel/incentives   \n",
      "31                                    Civil engineers   \n",
      "32      Fresher jobs for Customer care CCE Telecaller   \n",
      "33  work from home Fresh Graduate Front Office Exe...   \n",
      "34                            Opening For TEAM LEADER   \n",
      "35                  Visa specialist- Delhi 9717299688   \n",
      "36                               Full Stack Developer   \n",
      "37               Channel Sales Manager/ Sales Manager   \n",
      "38  Admin Manager (Office Administration) - Delhi ...   \n",
      "39  PART TIME , . , . ,UNDERGRADUATE , work from h...   \n",
      "40                                     Civil Engineer   \n",
      "41                                      Site Engineer   \n",
      "42                                       Receptionist   \n",
      "43                              Data Entry Supervisor   \n",
      "44                         Mechanical Design Engineer   \n",
      "45                  RA-CSR-Cyber-DP-Cons-Data Privacy   \n",
      "46                                  Account Executive   \n",
      "47  HIRING FOR FOOD QUALITY ASSURANCE MANAGER (DELHI)   \n",
      "48                                 Office Coordinator   \n",
      "49              PMO (Financial Management) - AM - GGN   \n",
      "\n",
      "                                              Company  \\\n",
      "0   Seema Gupta (Proprietor of Seema & Tarun Recru...   \n",
      "1                                       Global Linker   \n",
      "2                           Company Name Confidential   \n",
      "3                           Company Name Confidential   \n",
      "4                           Company Name Confidential   \n",
      "5                           Company Name Confidential   \n",
      "6                           Company Name Confidential   \n",
      "7                           Company Name Confidential   \n",
      "8                           Company Name Confidential   \n",
      "9                           Company Name Confidential   \n",
      "10                                      Global Linker   \n",
      "11                                        Back Office   \n",
      "12                                  Computer Operator   \n",
      "13                            CiB Net Station Sdn Bhd   \n",
      "14                                    Future Plannerz   \n",
      "15              Proximity Immigration Private Limited   \n",
      "16                                          Executive   \n",
      "17                    Ral Infosystems Private Limited   \n",
      "18                   Rudraksha Fire Security Services   \n",
      "19                           Ideslabs Private Limited   \n",
      "20                          Company Name Confidential   \n",
      "21                      Gvms Infotech Private Limited   \n",
      "22                             Metro Jobs Consultants   \n",
      "23                             Metro Jobs Consultants   \n",
      "24                 Locuz Enterprise Solutions Limited   \n",
      "25                             Metro Jobs Consultants   \n",
      "26                          Company Name Confidential   \n",
      "27                             Metro Jobs Consultants   \n",
      "28                             Metro Jobs Consultants   \n",
      "29                             Metro Jobs Consultants   \n",
      "30                                Xistence Consultant   \n",
      "31        Freelancer - Purushottam Munjajirao Dhutraj   \n",
      "32                                          Telesales   \n",
      "33                          Company Name Confidential   \n",
      "34               Silaris Informations Private Limited   \n",
      "35          Flight To Sucess Immigration Services Llp   \n",
      "36            Sourcebase Technologies Private Limited   \n",
      "37             Halwasiya Developments Private Limited   \n",
      "38             Halwasiya Developments Private Limited   \n",
      "39                Freelancer Harish Kumar Ksheersagar   \n",
      "40                             Metro Jobs Consultants   \n",
      "41                             Metro Jobs Consultants   \n",
      "42                             Metro Jobs Consultants   \n",
      "43                 Freelancer Donal RichyOlala Onkoro   \n",
      "44        Freelancer - Purushottam Munjajirao Dhutraj   \n",
      "45                                           Deloitte   \n",
      "46                             Metro Jobs Consultants   \n",
      "47                             Shreyas Group Services   \n",
      "48                                          HR Factor   \n",
      "49              Sampoorna Consultants Private Limited   \n",
      "\n",
      "                                             location  \\\n",
      "0                                   Delhi, Hyderab...   \n",
      "1                                        Delhi, Noida   \n",
      "2                                   Delhi, Mumbai,...   \n",
      "3                                      Chennai, Delhi   \n",
      "4                                   Bengaluru / Ba...   \n",
      "5                                   Delhi, Mumbai,...   \n",
      "6                                      Chennai, Delhi   \n",
      "7                                   Bengaluru / Ba...   \n",
      "8                                   Delhi, Hyderab...   \n",
      "9                                   Delhi, Hyderab...   \n",
      "10                                              Delhi   \n",
      "11                                       Delhi, Noida   \n",
      "12                                       Delhi, Noida   \n",
      "13                                              Delhi   \n",
      "14                                  Delhi, Gurgaon...   \n",
      "15                                              Delhi   \n",
      "16                                  Bengaluru / Ba...   \n",
      "17                                       Delhi, Noida   \n",
      "18                                       Delhi, Noida   \n",
      "19                                  Bengaluru / Ba...   \n",
      "20                                              Delhi   \n",
      "21                                  Delhi, Gurgaon...   \n",
      "22                                  Delhi, Gurgaon...   \n",
      "23                                  Delhi, Gurgaon...   \n",
      "24                                      Delhi, Mumbai   \n",
      "25                                              Delhi   \n",
      "26                                              Delhi   \n",
      "27                                              Delhi   \n",
      "28                                              Delhi   \n",
      "29                                              Delhi   \n",
      "30                                  Delhi, Gurgaon...   \n",
      "31                                      Delhi, Mumbai   \n",
      "32                                       Delhi, Noida   \n",
      "33                                  Delhi, Gurgaon...   \n",
      "34                                              Delhi   \n",
      "35                                              Delhi   \n",
      "36                                  Delhi, Gurgaon...   \n",
      "37                                              Delhi   \n",
      "38                                              Delhi   \n",
      "39                                  Delhi, Gurgaon...   \n",
      "40                                              Delhi   \n",
      "41                                              Delhi   \n",
      "42                                              Delhi   \n",
      "43                                      Delhi, Mumbai   \n",
      "44                                      Delhi, Mumbai   \n",
      "45                                       Delhi, India   \n",
      "46                                              Delhi   \n",
      "47                                              Delhi   \n",
      "48                                              Delhi   \n",
      "49                                  Delhi, Gurgaon...   \n",
      "\n",
      "                                      Experience  \\\n",
      "0                                    0-5 Years     \n",
      "1                                    0-5 Years     \n",
      "2                                    0-5 Years     \n",
      "3                                    0-5 Years     \n",
      "4                                    0-5 Years     \n",
      "5                                    0-5 Years     \n",
      "6                                    0-5 Years     \n",
      "7                                    0-5 Years     \n",
      "8                                    0-5 Years     \n",
      "9                                    0-5 Years     \n",
      "10                                   0-1 Years     \n",
      "11                                   0-5 Years     \n",
      "12                                   0-4 Years     \n",
      "13                                   1-5 Years     \n",
      "14                                   1-6 Years     \n",
      "15                                   1-6 Years     \n",
      "16                                   2-4 Years     \n",
      "17                                  3-12 Years     \n",
      "18                                  1-11 Years     \n",
      "19                                  4-14 Years     \n",
      "20                                  3-10 Years     \n",
      "21                                   3-8 Years     \n",
      "22                                  5-15 Years     \n",
      "23                                 15-25 Years     \n",
      "24                                   3-8 Years     \n",
      "25                                 10-15 Years     \n",
      "26                                  6-10 Years     \n",
      "27                                  5-10 Years     \n",
      "28                                  5-15 Years     \n",
      "29                                 10-20 Years     \n",
      "30                                   0-5 Years     \n",
      "31                                   2-7 Years     \n",
      "32                                   0-3 Years     \n",
      "33                                   0-5 Years     \n",
      "34                                  3-10 Years     \n",
      "35                                  1-10 Years     \n",
      "36                                  5-10 Years     \n",
      "37                                   5-7 Years     \n",
      "38                                   3-4 Years     \n",
      "39                                   0-5 Years     \n",
      "40                                   0-5 Years     \n",
      "41                                   0-5 Years     \n",
      "42                                   1-5 Years     \n",
      "43                                  1-11 Years     \n",
      "44                                   2-7 Years     \n",
      "45                               Not Specified     \n",
      "46                                   1-2 Years     \n",
      "47                                  3-13 Years     \n",
      "48                                   2-4 Years     \n",
      "49                                  5-10 Years     \n",
      "\n",
      "                                               Salary  \n",
      "0                                   1,20,000-3,60,...  \n",
      "1                                   2,20,000-4,40,...  \n",
      "2                                       Not Specified  \n",
      "3                                       Not Specified  \n",
      "4                                       Not Specified  \n",
      "5                                       Not Specified  \n",
      "6                                       Not Specified  \n",
      "7                                       Not Specified  \n",
      "8                                       Not Specified  \n",
      "9                                       Not Specified  \n",
      "10                                  1,00,000-2,00,...  \n",
      "11                                  80,000-2,50,00...  \n",
      "12                                  80,000-2,50,00...  \n",
      "13                                      Not Specified  \n",
      "14                                      Not Specified  \n",
      "15                                  2,00,000-3,50,...  \n",
      "16                                      Not Specified  \n",
      "17                                      Not Specified  \n",
      "18                                  2,50,000-6,50,...  \n",
      "19                                      Not Specified  \n",
      "20                                  3,00,000-5,00,...  \n",
      "21                                      Not Specified  \n",
      "22                                      Not Specified  \n",
      "23                                      Not Specified  \n",
      "24                                      Not Specified  \n",
      "25                                      Not Specified  \n",
      "26                                  10,80,000-20,8...  \n",
      "27                                      Not Specified  \n",
      "28                                      Not Specified  \n",
      "29                                      Not Specified  \n",
      "30                                      Not Specified  \n",
      "31                                  3,50,000-7,80,...  \n",
      "32                                  80,000-3,00,00...  \n",
      "33                                  80,000-2,80,00...  \n",
      "34                                      Not Specified  \n",
      "35                                  1,20,000-1,80,...  \n",
      "36                                      Not Specified  \n",
      "37                                      Not Specified  \n",
      "38                                  3,00,000-3,60,...  \n",
      "39                                      Not Specified  \n",
      "40                                      Not Specified  \n",
      "41                                      Not Specified  \n",
      "42                                      Not Specified  \n",
      "43                                  4,50,000-21,80...  \n",
      "44                                  2,29,999-10,80...  \n",
      "45                                      Not Specified  \n",
      "46                                      Not Specified  \n",
      "47                                      Not Specified  \n",
      "48                                      Not Specified  \n",
      "49                                      Not Specified  \n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def data_sci(url):\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\HP\\Desktop\\Data Trained\\Flip Robo\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    start_page=0\n",
    "    end_page=4\n",
    "    urls=[]\n",
    "    job_names=[]\n",
    "    company=[]\n",
    "    location=[]\n",
    "    experience=[]\n",
    "    salary=[]\n",
    "    for page in range(start_page,end_page+1):\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        jobs=soup.find_all('div', attrs ={'class':'job-tittle'})\n",
    "        for job in jobs:\n",
    "            l=job.text.split('\\n')\n",
    "            job_names.append(l[0].split('  ')[0])\n",
    "            company.append(l[0].split('  ')[1])\n",
    "            location.append(l[1])\n",
    "            experience.append(l[2])\n",
    "            salary.append(l[3])\n",
    "    \n",
    "        nxt_button=driver.find_element_by_xpath(\"//button[@class='btn-next-prev btn-next']\")\n",
    "        if nxt_button.text=='Next':\n",
    "            nxt_button.click()\n",
    "            time.sleep(5)\n",
    "\n",
    "    job_df=pd.DataFrame({'Job_Names':job_names,\n",
    "                         'Company':company,\n",
    "                         'location':location,\n",
    "                         'Experience':experience,\n",
    "                         'Salary':salary})\n",
    "    job_df.to_csv('Data Scientist_ND_Monster', index = False)\n",
    "    print(job_df)\n",
    "\n",
    "# Calling Function\n",
    "data_sci(\"https://www.monsterindia.com/srp/results?query=Data%20Scientist&locations=Delhi&searchId=ebc9a3bb-97c5-4647-8eac-ad5d9d92d3fc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Document"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
